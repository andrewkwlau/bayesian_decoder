{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../library'))\n",
    "import data as d\n",
    "import preprocess as p\n",
    "import utils as u\n",
    "import bayes as b\n",
    "import pipeline_npxl as npxl\n",
    "import results as r\n",
    "import figures as figs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo on using the decoder for Neuropixel data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Initialise NpxlData object\n",
    "\n",
    "Here, we initialise a `NpxlData` object (from `data.py`) with the following attributes:\n",
    "\n",
    "- `mouse_ID` is the name of the \"mouse\". You can also be specific and write the session and the brain area, etc.\n",
    "- `tau` is the size of time bin in seconds. 0.2 = 200ms.\n",
    "- `ms` is just converting `tau` back into `str` and in miliseconds to load the data later.\n",
    "- `rewardzone` is self explnatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ID = 'VDCN09_20240729'     # e.g. can also be 'VDCN09_200ms_BSC'\n",
    "tau = 0.2\n",
    "ms = str(int(tau * 1000))\n",
    "rewardzone = np.arange(46,62).tolist()\n",
    "VDCN09 = d.NpxlData(mouse_ID, tau, rewardzone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Loading data\n",
    "\n",
    "- change areas as required\n",
    "- change filepath as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = ['midbrain', 'LP', 'vispm', 'hpf', 'DG', 'LGNd', 'BSC', 'lower', 'v1']\n",
    "area = 'vispm'\n",
    "\n",
    "data_fr_lgt = np.load(\"../datafiles/Neuropixel/20240729/20240729_az_VDCN09_imec0_725_\"+ area +\"_200ms_spike_rate.npz\")\n",
    "data_fr_drk = np.load(\"../datafiles/Neuropixel/20240729/20240729_az_VDCN09_imec0_1322_\"+ area +\"_200ms_spike_rate.npz\")\n",
    "\n",
    "data_count_lgt = np.load(\"../datafiles/Neuropixel/20240729/20240729_az_VDCN09_imec0_725_\"+ area +\"_200ms_spike_count.npz\")\n",
    "data_count_drk = np.load(\"../datafiles/Neuropixel/20240729/20240729_az_VDCN09_imec0_1322_\"+ area +\"_200ms_spike_count.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_shuffled_lgt = np.load(\"../datafiles/Neuropixel/shuffled/20240812_az_VDCN09_imec0_light_all_spike_counts_shuffled_200ms_10cm.npz\")\n",
    "count_shuffled_drk = np.load(\"../datafiles/Neuropixel/shuffled/20240812_az_VDCN09_imec0_dark_all_spike_counts_shuffled_200ms_10cm.npz\")\n",
    "\n",
    "fr_shuffled_lgt = np.load(\"../datafiles/Neuropixel/shuffled/20240812_az_VDCN09_imec0_light_all_fr_shuffled_200ms_10cm.npz\")\n",
    "fr_shuffled_drk = np.load(\"../datafiles/Neuropixel/shuffled/20240812_az_VDCN09_imec0_dark_all_fr_shuffled_200ms_10cm.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Defining the mouse\n",
    "\n",
    "From here onwards, new attributes will be defined for a given `NpxlData` object.\n",
    "To avoid manually changing it everytime we run a new mouse or new session, we will define\n",
    "it here. Although it is said to be a `mouse`, again it can mean a specific sesion or\n",
    "a specific brain area you are running, depending on how you initialise it earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = VDCN09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Preprocessing data\n",
    "\n",
    "Pre-processing data steps:\n",
    "- swapping axes to make it (Trial, Tbin, Neurons)\n",
    "- defining position matrices\n",
    "- correcting position matrix artifacts\n",
    "- inspect trial start location (to see if there are further artifacts)\n",
    "\n",
    "\n",
    "Pre-processing shuffled data steps:\n",
    "- swapping axes to make it (Trial, Tbin, Neurons, Reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap axes\n",
    "mouse.spikes_lgt = np.swapaxes(data_count_lgt['count'], 1,2)\n",
    "mouse.spikes_drk = np.swapaxes(data_count_drk['count'], 1,2)\n",
    "\n",
    "mouse.fr_lgt = np.swapaxes(data_fr_lgt['fr'], 1,2)\n",
    "mouse.fr_drk = np.swapaxes(data_fr_drk['fr'], 1,2)\n",
    "\n",
    "# Defining position matrix\n",
    "mouse.pos_lgt = data_count_lgt['pos'][:,1,:]\n",
    "mouse.pos_drk = data_count_drk['pos'][:,1,:]\n",
    "\n",
    "print(\"Trial, Time Bins, Neurons\")\n",
    "print(mouse.spikes_lgt.shape)\n",
    "print(mouse.fr_lgt.shape)\n",
    "print(mouse.pos_lgt.shape)\n",
    "print(mouse.spikes_drk.shape)\n",
    "print(mouse.fr_drk.shape)\n",
    "print(mouse.pos_drk.shape)\n",
    "print(mouse.__dict__.keys())\n",
    "\n",
    "# Inspect trial start location\n",
    "trialstart_lgt = []\n",
    "trialstart_drk = []\n",
    "\n",
    "for trial in range(mouse.pos_lgt.shape[0]):\n",
    "    trialstart_lgt.append(VDCN09.pos_lgt[trial,0])\n",
    "for trial in range(mouse.pos_drk.shape[0]):\n",
    "    trialstart_drk.append(VDCN09.pos_drk[trial,0])\n",
    "\n",
    "start_location_lgt = np.unique(trialstart_lgt)\n",
    "start_location_drk = np.unique(trialstart_drk)\n",
    "\n",
    "print('start locations lgt:', start_location_lgt)\n",
    "print(trialstart_lgt)\n",
    "print()\n",
    "print('start locations drk:', start_location_drk)\n",
    "print(trialstart_drk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting position matrix artifacts\n",
    "\n",
    "# VDCN09 20240812 200ms\n",
    "# mouse.pos_lgt[96,0] = 1\n",
    "# mouse.pos_lgt[112,:2] = 16\n",
    "# mouse.pos_lgt[19,0] = 16     # for 250ms bins of VDCN09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VDCN09 20240729 200ms\n",
    "correct_start = [1, 4, 8, 11, 15, 18, 22, 25, 29, 32, 36]\n",
    "wrong_start = [5, 12, 19, 26, 33]\n",
    "\n",
    "wrong_trials_lgt = {}\n",
    "wrong_trials_drk = {}\n",
    "\n",
    "for pos in wrong_start:\n",
    "    wrong_trials_lgt[pos] = np.where(mouse.pos_lgt[:,0] == pos)[0]\n",
    "    wrong_trials_drk[pos] = np.where(mouse.pos_drk[:,0] == pos)[0]\n",
    "\n",
    "\n",
    "# Mapping from wrong to correct start positions\n",
    "shift_map = {5: 4, 12: 11, 19: 18, 26: 25, 33: 32}\n",
    "\n",
    "# Correct pos_lgt\n",
    "for wrong_pos, trial_indices in wrong_trials_lgt.items():\n",
    "    correct_pos = shift_map[wrong_pos]\n",
    "    mouse.pos_lgt[trial_indices, 0] = correct_pos\n",
    "\n",
    "# Correct pos_drk\n",
    "for wrong_pos, trial_indices in wrong_trials_drk.items():\n",
    "    correct_pos = shift_map[wrong_pos]\n",
    "    mouse.pos_drk[trial_indices, 0] = correct_pos\n",
    "\n",
    "# Inspect trial start location again\n",
    "trialstart_lgt = []\n",
    "trialstart_drk = []\n",
    "\n",
    "for trial in range(mouse.pos_lgt.shape[0]):\n",
    "    trialstart_lgt.append(VDCN09.pos_lgt[trial,0])\n",
    "for trial in range(mouse.pos_drk.shape[0]):\n",
    "    trialstart_drk.append(VDCN09.pos_drk[trial,0])\n",
    "\n",
    "start_location_lgt = np.unique(trialstart_lgt)\n",
    "start_location_drk = np.unique(trialstart_drk)\n",
    "\n",
    "print('start locations lgt:', start_location_lgt)\n",
    "print(trialstart_lgt)\n",
    "print()\n",
    "print('start locations drk:', start_location_drk)\n",
    "print(trialstart_drk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess shuffled data\n",
    "\n",
    "mouse.spikes_shuffled_lgt = np.swapaxes(np.swapaxes(count_shuffled_lgt['count'], 1,2), 0,1)\n",
    "mouse.spikes_shuffled_drk = np.swapaxes(np.swapaxes(count_shuffled_drk['count'], 1,2), 0,1)\n",
    "\n",
    "mouse.fr_shuffled_lgt = np.swapaxes(np.swapaxes(fr_shuffled_lgt['fr'], 1,2), 0,1)\n",
    "mouse.fr_shuffled_drk = np.swapaxes(np.swapaxes(fr_shuffled_drk['fr'], 1,2), 0,1)\n",
    "\n",
    "print(\"Trial, Time Bins, Neurons, Reps\")\n",
    "print(mouse.spikes_shuffled_lgt.shape)\n",
    "print(mouse.spikes_shuffled_drk.shape)\n",
    "print(mouse.fr_shuffled_lgt.shape)\n",
    "print(mouse.fr_shuffled_drk.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running decoder and results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Running decoder in chunks of trials\n",
    "\n",
    "Essentially, the pipeline `npxl.run_decoder_chunks()` sorts and chunks the data by\n",
    "trial start locations, run them separately, then concatenate back the `posterior` and\n",
    "`decoded_pos` for a given `mouse`.\n",
    "\n",
    "Outputs are `dicts` with paradigms as keys `['lgtlgt', 'drkdrk', 'lgtdrk', 'drklgt']`, as an example:\n",
    "- `posterior['lgtlgt']` has shape (Trial, Time bins, Position Bins)\n",
    "- `decoded_pos['lgtlgt']` has shape (Trial, Time bins)\n",
    "\n",
    "Key functions under the hood:\n",
    "- `npxl.get_tuning_curves()` which is a wrapper for masking, smoothing (if required), and binning firing rates into spatial tuning curves.\n",
    "- `u.sort_and_chunk()` for sorting and chunking data, position matrices, etc.\n",
    "- `b.bayesian_decoder_chunks()` which is the main decoder function.\n",
    "\n",
    "Properties and their default values:\n",
    "- `mouse`: the NpxlData object\n",
    "- `x`: the number of position bins to mask in the beginning of the tunnel. Default is `5` = 50cm.\n",
    "- `tunnellength`: Used for position binning spatial tuning curves. Default is `50` position bins.\n",
    "- `num_pbins`: Tunnel length excluding the reward zone. Default is `46` position bins.\n",
    "- `smooth`: Whether to position bin spikes to get firingrate tuning curves. Default is `False` as spikerate is often provided.\n",
    "- `SDfrac`: For computing sigma, see `u.compute_sigma()`. Default is `0.2`.\n",
    "- `scale`: Whether to scale firing rates, see `u.scale_firingrate()` Default is `True`.\n",
    "- `uniformprior`: If `True`, prior = 1 / num_pbins for all trials. Default is `False`, where prior = 1 / triallength.\n",
    "- `discrete`: Trial start have discrete location instead of continuous (in some of Alfredo's mice). Default is `True`.\n",
    "- `num_chunks`: Number of chunks that have different start locations. Default is `6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse.posterior, mouse.decoded_pos = npxl.run_decoder_chunks(mouse, num_chunks=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generating decoding results from posterior and decoded_pos\n",
    "\n",
    "Result types:\n",
    "- `'confusion_mtx'`: A 46 by 46 matrix. Vertical axis is True position, Horizontal axis is Decoded position.\n",
    "- `'mean_accuracy'`: An average across trials of mean accuracy per trial.\n",
    "- `'mean_error'`: An average across trials of mean error per trial.\n",
    "- `'median_error'`: An average across trials of median error per trial.\n",
    "- `'rt_mse'`: An average across trials of root mean squared error per trial.\n",
    "- `'mean_wt_error'`: An average across trials of weighted error by posterior per trial.\n",
    "- `'MostFreqPred_error'`: An average across position bins of errors between true position and most frequently decoded position.\n",
    "\n",
    "Output are nested `dict` with result type on the first level and paradigms on the second level, examples:\n",
    "- `results['confusion_mtx']['lgtlgt']` has shape (46, 46)\n",
    "- `results['mean_accuracy']['lgtlgt']` is a single float\n",
    "- `results['mean_error']['lgtlgt']` is a single float\n",
    "\n",
    "Properties and their default values:\n",
    "- `mouse`: the NpxlData object\n",
    "- `num_chunks`: Number of chunks that have different start locations. Default is `6`.\n",
    "- `num_pbins`: Tunnel length excluding the reward zone. Default is `46` position bins.\n",
    "- `discrete`: Trial start have discrete location instead of continuous (in some of Alfredo's mice). Default is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse.results = npxl.run_results_chunks(mouse, num_chunks=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Generating output DataFrame/CSV and plotting Confusion Matrices\n",
    "\n",
    "DataFrame can be output as CSV. Change file path as required.\n",
    "\n",
    "For confusion matrices, the figure can be saved if toggle `save=True`. Default is `False`. `filepath` default is `None`. Change it as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating output DataFrame\n",
    "paradigms = ['lgtlgt', 'drkdrk', 'lgtdrk', 'drklgt']\n",
    "data = {key: [mouse.results[key][p] for p in paradigms] for key in mouse.results if key != 'confusion_mtx'}\n",
    "df = pd.DataFrame(data, index=paradigms)\n",
    "df.index.name = 'paradigm'\n",
    "\n",
    "# Export DataFrame to CSV\n",
    "df.to_csv(\"../results/csv/\"+ mouse.mouse_ID +\"_\"+ ms +\"ms_\"+ area +\"_results.csv\")\n",
    "display(df)\n",
    "\n",
    "# Plot confusion matrix\n",
    "for paradigm in paradigms:\n",
    "    filepath = '../results/figures/'+ mouse.mouse_ID +'_'+ ms +'ms_'+ area +'_confusion_mtx_'+ paradigm +'.png'\n",
    "    # Option to save the figure. If True, save to filepath.\n",
    "    figs.plot_confusion_mtx(mouse, mouse.results['confusion_mtx'][paradigm], paradigm, True, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running Chance Estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Running decoder chance pipeline\n",
    "\n",
    "\n",
    "Essentially, same as `npxl.run_decoder_chunks()` but for multiple reps. Note that `npxl.run_decoder_chunks()` is a prerequisite before running the chance pipeline.\n",
    "\n",
    "Outputs are saved with `pickle` to save time from running it again in the future.\n",
    "\n",
    "Outputs are `list` containing `dict` for each rep with paradigms as keys `['lgtlgt', 'drkdrk', 'lgtdrk', 'drklgt']`, as an example:\n",
    "- `posterior_allreps[0]['lgtlgt']` is posterior of rep 0 with shape (Trial, Time bins, Position Bins)\n",
    "- `decoded_pos_allreps[0]['lgtlgt']` is decoded_pos of rep 0 with shape (Trial, Time bins)\n",
    "\n",
    "Additional properties on top of those in `npxl.run_decoder_chunks()`:\n",
    "- `num_reps`: Default is `100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse.posterior_allreps, mouse.decoded_pos_allreps = npxl.run_decoder_chance(mouse, num_chunks=6, smooth=False)\n",
    "\n",
    "with open('../variables/'+ mouse.mouse_ID +'_'+ ms +'_posterior_allreps.pkl', 'wb') as f:\n",
    "    pickle.dump(mouse.posterior_allreps, f)\n",
    "\n",
    "with open('../variables/'+ mouse.mouse_ID +'_'+ ms +'_decoded_pos_allreps.pkl', 'wb') as f:\n",
    "    pickle.dump(mouse.decoded_pos_allreps, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Running chance results pipeline\n",
    "\n",
    "Essentially, same as `npxl.run_results_chunks()` but for multiple reps. Only difference is it does not have confusion matrices in the output.\n",
    "\n",
    "Outputs are saved with `pickle`.\n",
    "\n",
    "Result types:\n",
    "- `'mean_accuracy_allreps'`: An average across trials of mean accuracy per trial.\n",
    "- `'mean_error_allreps'`: An average across trials of mean error per trial.\n",
    "- `'median_error_allreps'`: An average across trials of median error per trial.\n",
    "- `'rt_mse_allreps'`: An average across trials of root mean squared error per trial.\n",
    "- `'mean_wt_error_allreps'`: An average across trials of weighted error by posterior per trial.\n",
    "- `'MostFreqPred_error_allreps'`: An average across position bins of errors between true position and most frequently decoded position.\n",
    "\n",
    "Within each result type is a `list` of `dict`, examples:\n",
    "- `results_allreps['mean_accuracy_allreps'][0]['lgtlgt']` is a single float\n",
    "- `results['mean_error_allreps'][0]['lgtlgt']` is a single float\n",
    "\n",
    "Additional properties on top of those in `npxl.run_results_chunks()`:\n",
    "- `num_reps`: Default is `100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse.results_allreps = npxl.run_results_chance(mouse, num_chunks=6)\n",
    "\n",
    "with open('../variables/'+ mouse.mouse_ID +'_'+ ms +'_results_allreps.pkl', 'wb') as f:\n",
    "    pickle.dump(mouse.results_allreps, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
